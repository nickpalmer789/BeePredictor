{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_flow = pd.read_csv(\"data/raw/schwartau/flow_schwartau.csv\")\n",
    "test_flow = sch_flow\n",
    "sch_temp = pd.read_csv(\"data/raw/schwartau/temperature_schwartau.csv\")\n",
    "test_sch = sch_temp\n",
    "sch_humid = pd.read_csv(\"data/raw/schwartau/humidity_schwartau.csv\")\n",
    "sch_weight = pd.read_csv(\"data/raw/schwartau/weight_schwartau.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pls love me I need it to survive -Derek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for flow:\n",
    "\n",
    "* Lots of zero data\n",
    "* Measured every minute. Need to aggregate\n",
    "* Negative numbers are bee departures\n",
    "* Positive numbers are bee arrivals\n",
    "* Keep arrivals and departures separate \n",
    "\n",
    "I separated by every 15 like the temp data and then created 2 df copies for all arrivals and all departures.  DONE-Derek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe: \n",
      "             timestamp  flow\n",
      "0  2017-01-01 14:15:00     0\n",
      "1  2017-01-01 14:16:00     0\n",
      "2  2017-01-01 14:17:00     0\n",
      "3  2017-01-01 14:18:00     0\n",
      "4  2017-01-01 14:19:00     0\n",
      "\n",
      "New dataframe:\n",
      "            timestamp  flow  departures  arrivals\n",
      "0 2017-01-01 14:15:00     0           0         0\n",
      "1 2017-01-01 14:30:00     0           0         0\n",
      "2 2017-01-01 14:45:00     0           0         0\n",
      "3 2017-01-01 15:00:00     0           0         0\n",
      "4 2017-01-01 15:15:00     0           0         0\n",
      "\n",
      "You are a coding master! No problems detected!\n"
     ]
    }
   ],
   "source": [
    "#original flow\n",
    "print(\"Original dataframe: \")\n",
    "print(test_flow.head())\n",
    "print()\n",
    "\n",
    "#Required changes:\n",
    "#Rather than dropping all data that doesn't occur every 15 minutes, we need to sum up departures and arrivals\n",
    "#that occur in each 15 minute timespan. \n",
    "\n",
    "#Track which indexes should be dropped\n",
    "dropList = []\n",
    "\n",
    "#Drop N/A data points\n",
    "sch_flow = sch_flow.dropna()\n",
    "\n",
    "#Convert the timestamps to date time objects\n",
    "sch_flow['timestamp'] = pd.to_datetime(sch_flow['timestamp'])\n",
    "\n",
    "#Create columns for departures and arrivals\n",
    "sch_flow['departures'] = sch_flow['flow']\n",
    "sch_flow['arrivals'] = sch_flow['flow']\n",
    "\n",
    "#Counters for arrivals in each 15 minute interval\n",
    "arrivals = 0\n",
    "departures = 0\n",
    "total_flow = 0\n",
    "\n",
    "#Set the length of the interval\n",
    "interval_length = 15\n",
    "\n",
    "for ind,minute in sch_flow['timestamp'].dt.minute.items():   \n",
    "    #Count the toal flow, departures, and arrival for the current interval\n",
    "    current_flow = sch_flow.at[ind, 'flow']\n",
    "    total_flow += current_flow\n",
    "    if(current_flow < 0):\n",
    "        #Departures are negative flow numbers\n",
    "        departures += abs(current_flow)\n",
    "    else:\n",
    "        arrivals += current_flow\n",
    "    \n",
    "    #Set the values at each 15 minute interval\n",
    "    if(minute % interval_length == 0):\n",
    "        #Set total flow\n",
    "        sch_flow.at[ind, 'flow'] = total_flow\n",
    "        \n",
    "        #Set departures \n",
    "        sch_flow.at[ind, 'departures'] = departures\n",
    "        \n",
    "        #Set arrivals\n",
    "        sch_flow.at[ind, 'arrivals'] = arrivals\n",
    "        \n",
    "        #Reset the counters\n",
    "        total_flow = 0\n",
    "        departures = 0\n",
    "        arrivals = 0\n",
    "    \n",
    "    #Mark indexes that aren't at 15 minute intervals to be dropped\n",
    "    if (minute % interval_length != 0):\n",
    "        dropList.append(ind)\n",
    "\n",
    "#Drop indexes marked for dropping\n",
    "sch_flow = sch_flow.drop(index = dropList)\n",
    "\n",
    "sch_flow.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Display some information about the new dataframe\n",
    "print(\"New dataframe:\")\n",
    "print(sch_flow.head())\n",
    "print()\n",
    "\n",
    "\n",
    "#Do a quick sanity check that the above operation actually worked\n",
    "#Testing your code is always good!\n",
    "flow_problem_flag = False #Detect problems with the flow calculations\n",
    "filtering_problem_flag = False #Detect problems with filtering out minutes that arent at 15 minute intervals\n",
    "problem_index = 0 #The index where the first problem occured\n",
    "flow_gotten = 0 # The number that the flow actually came out to\n",
    "flow_actual = 0 # The actual flow\n",
    "for ind,minute in sch_flow['timestamp'].dt.minute.items():\n",
    "    \n",
    "    #Add the arrivals and departures\n",
    "    #These should be the same as the total flow\n",
    "    current_count = 0\n",
    "    current_count += sch_flow.at[ind, 'arrivals'] #Arrivals are counted as positive 'flow'\n",
    "    current_count -= sch_flow.at[ind, 'departures'] #Departures are counted as negative 'flow'\n",
    "    \n",
    "    #Check that arrivals are \n",
    "    if(current_count != sch_flow.at[ind, 'flow']):\n",
    "        flow_problem_flag = True\n",
    "        problem_index = ind\n",
    "        flow_gotten = current_count\n",
    "        flow_actual = sch_flow.at[ind, 'flow']\n",
    "        break\n",
    "    \n",
    "    if(minute % interval_length != 0):\n",
    "        filtering_problem_flag = True\n",
    "        problem_index = ind\n",
    "        break\n",
    "    \n",
    "if(flow_problem_flag):\n",
    "    print(\"Looks like you have a flow problem at index: \" + str(problem_index) + \"! Have fun with that...\")\n",
    "    print(\"The flow count gotten: \" + str(flow_gotten))\n",
    "    print(\"The flow count expected: \" + str(flow_actual))\n",
    "elif(filtering_problem_flag):\n",
    "    print(\"Looks like you have a time filtering problem at index: \" + str(problem_index) + \"! Have fun with that...\")\n",
    "else:\n",
    "    print(\"You are a coding master! No problems detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for temperature:\n",
    "\n",
    "* May contain NaN (Dropped rows containing these.  DONE-Derek)\n",
    "* Measured in degrees celsius (Will leave as C unless otherwise stated.  DONE-Derek)\n",
    "* Measured every 5 minutes (coverted to every 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  temperature\n",
      "0  2017-01-01 14:10:00          NaN\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "2  2017-01-01 14:20:00       12.270\n",
      "3  2017-01-01 14:25:00       12.276\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "\n",
      "253430\n",
      "\n",
      "251398\n",
      "\n",
      "             timestamp  temperature\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "2  2017-01-01 14:20:00       12.270\n",
      "3  2017-01-01 14:25:00       12.276\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "5  2017-01-01 14:35:00       12.404\n",
      "\n",
      "             timestamp  temperature\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "7  2017-01-01 14:45:00       12.492\n",
      "10 2017-01-01 15:00:00       12.454\n",
      "13 2017-01-01 15:15:00       12.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svand\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Preview of temp\n",
    "print(test_sch.head())\n",
    "print()\n",
    "#Initial number of values\n",
    "print(len(test_sch.index))\n",
    "#Drop NaN value rows\n",
    "sch_tempFilter = test_sch.dropna()\n",
    "print()\n",
    "#Number of values after\n",
    "print(len(sch_tempFilter.index))\n",
    "print()\n",
    "print(sch_tempFilter.head())\n",
    "print()\n",
    "\n",
    "#Sorting timestamp...\n",
    "tempList = []\n",
    "sch_temp = sch_temp.dropna()\n",
    "sch_temp['timestamp'] = pd.to_datetime(sch_temp['timestamp'])\n",
    "for ind,minute in sch_temp['timestamp'].dt.minute.items():\n",
    "    if (minute %15 != 0):\n",
    "        tempList.append(ind)\n",
    "sch_temp = sch_temp.drop(index = tempList)\n",
    "\n",
    "#sch_temp.reset_index()\n",
    "\n",
    "print(sch_temp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for humidity:\n",
    "\n",
    "* Measured in percentage\n",
    "* Measured twice per day\n",
    "* May need to be suplimented with other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 13:00:00</td>\n",
       "      <td>98.040310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>98.610556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-02 13:00:00</td>\n",
       "      <td>99.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-03 01:00:00</td>\n",
       "      <td>98.486806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-03 13:00:00</td>\n",
       "      <td>98.320139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp   humidity\n",
       "0  2017-01-01 13:00:00  98.040310\n",
       "1  2017-01-02 01:00:00  98.610556\n",
       "2  2017-01-02 13:00:00  99.002083\n",
       "3  2017-01-03 01:00:00  98.486806\n",
       "4  2017-01-03 13:00:00  98.320139"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch_humid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for weight:\n",
    "\n",
    "* Measured twice per day. Need some creative solution here\n",
    "* Potential to correlate with flow?\n",
    "* The weight for schwartau needs to be divided by 1000. It was measured in grams accidentally. DONE-Derek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp        weight\n",
      "0  2017-01-01 13:00:00  50736.790078\n",
      "1  2017-01-02 01:00:00  50700.685000\n",
      "2  2017-01-02 13:00:00  50614.907500\n",
      "3  2017-01-03 01:00:00  50739.824167\n",
      "4  2017-01-03 13:00:00  50799.746944\n",
      "\n",
      "             timestamp     weight\n",
      "0  2017-01-01 13:00:00  50.736790\n",
      "1  2017-01-02 01:00:00  50.700685\n",
      "2  2017-01-02 13:00:00  50.614908\n",
      "3  2017-01-03 01:00:00  50.739824\n",
      "4  2017-01-03 13:00:00  50.799747\n"
     ]
    }
   ],
   "source": [
    "#original data\n",
    "test_weight = sch_weight\n",
    "print(test_weight.head())\n",
    "print()\n",
    "#fixing weight\n",
    "sch_weight[\"weight\"] = sch_weight[\"weight\"].div(1000)\n",
    "print(sch_weight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Finally, combine the cleaned dataset into one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Departure dataframe:\n",
      "Departure dataframe length: 167584\n",
      "                     flow  departures  arrivals\n",
      "timestamp                                      \n",
      "2017-01-01 14:15:00     0           0         0\n",
      "2017-01-01 14:30:00     0           0         0\n",
      "2017-01-01 14:45:00     0           0         0\n",
      "2017-01-01 15:00:00     0           0         0\n",
      "2017-01-01 15:15:00     0           0         0\n",
      "\n",
      "\n",
      "Temperature dataframe:\n",
      "Temperature dataframe length: 83800\n",
      "                     temperature\n",
      "timestamp                       \n",
      "2017-01-01 14:15:00       12.340\n",
      "2017-01-01 14:30:00       12.356\n",
      "2017-01-01 14:45:00       12.492\n",
      "2017-01-01 15:00:00       12.454\n",
      "2017-01-01 15:15:00       12.378\n",
      "\n",
      "\n",
      "Merged dataset:\n",
      "Merged dataset length: 167616\n",
      "                     flow  departures  arrivals  temperature\n",
      "timestamp                                                   \n",
      "2017-01-01 14:15:00     0           0         0       12.340\n",
      "2017-01-01 14:15:00     0           0         0       12.340\n",
      "2017-01-01 14:30:00     0           0         0       12.356\n",
      "2017-01-01 14:30:00     0           0         0       12.356\n",
      "2017-01-01 14:45:00     0           0         0       12.492\n",
      "2017-01-01 14:45:00     0           0         0       12.492\n",
      "2017-01-01 15:00:00     0           0         0       12.454\n",
      "2017-01-01 15:00:00     0           0         0       12.454\n",
      "2017-01-01 15:15:00     0           0         0       12.378\n",
      "2017-01-01 15:15:00     0           0         0       12.378\n",
      "2017-01-01 15:30:00     0           0         0       12.308\n",
      "2017-01-01 15:30:00     0           0         0       12.308\n",
      "2017-01-01 15:45:00     0           0         0       15.074\n",
      "2017-01-01 15:45:00     0           0         0       15.074\n",
      "2017-01-01 16:00:00     0           0         0       16.836\n",
      "2017-01-01 16:00:00     0           0         0       16.836\n",
      "2017-01-01 16:15:00     0           0         0       15.730\n",
      "2017-01-01 16:15:00     0           0         0       15.730\n",
      "2017-01-01 16:30:00     0           0         0       14.010\n",
      "2017-01-01 16:30:00     0           0         0       14.010\n",
      "2017-01-01 16:45:00     0           0         0       17.952\n",
      "2017-01-01 16:45:00     0           0         0       17.952\n",
      "2017-01-01 17:00:00     0           0         0       19.494\n",
      "2017-01-01 17:00:00     0           0         0       19.494\n",
      "2017-01-01 17:15:00     0           0         0       17.634\n",
      "2017-01-01 17:15:00     0           0         0       17.634\n",
      "2017-01-01 17:30:00     0           0         0       15.656\n",
      "2017-01-01 17:30:00     0           0         0       15.656\n",
      "2017-01-01 17:45:00     0           0         0       15.442\n",
      "2017-01-01 17:45:00     0           0         0       15.442\n",
      "...                   ...         ...       ...          ...\n",
      "2017-01-11 20:30:00     0           0         0       16.018\n",
      "2017-01-11 20:30:00     0           0         0       16.018\n",
      "2017-01-11 20:45:00     0           0         0       15.524\n",
      "2017-01-11 20:45:00     0           0         0       15.524\n",
      "2017-01-11 21:00:00     0           0         0       14.062\n",
      "2017-01-11 21:00:00     0           0         0       14.062\n",
      "2017-01-11 21:15:00     0           0         0       15.290\n",
      "2017-01-11 21:15:00     0           0         0       15.290\n",
      "2017-01-11 21:30:00     0           0         0       14.996\n",
      "2017-01-11 21:30:00     0           0         0       14.996\n",
      "2017-01-11 21:45:00     0           0         0       14.888\n",
      "2017-01-11 21:45:00     0           0         0       14.888\n",
      "2017-01-11 22:00:00     0           0         0       14.026\n",
      "2017-01-11 22:00:00     0           0         0       14.026\n",
      "2017-01-11 22:15:00     0           0         0       15.034\n",
      "2017-01-11 22:15:00     0           0         0       15.034\n",
      "2017-01-11 22:30:00     0           0         0       16.172\n",
      "2017-01-11 22:30:00     0           0         0       16.172\n",
      "2017-01-11 22:45:00     0           0         0       16.106\n",
      "2017-01-11 22:45:00     0           0         0       16.106\n",
      "2017-01-11 23:00:00    -1           1         0       16.240\n",
      "2017-01-11 23:00:00     0           0         0       16.240\n",
      "2017-01-11 23:15:00     0           0         0       15.502\n",
      "2017-01-11 23:15:00     0           0         0       15.502\n",
      "2017-01-11 23:30:00    -1           1         0       14.472\n",
      "2017-01-11 23:30:00     0           0         0       14.472\n",
      "2017-01-11 23:45:00    -1           1         0       16.076\n",
      "2017-01-11 23:45:00     0           0         0       16.076\n",
      "2017-01-12 00:00:00     0           0         0       15.156\n",
      "2017-01-12 00:00:00     0           0         0       15.156\n",
      "\n",
      "[2000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Display information about the flow dataset\n",
    "print(\"\\n\\nDeparture dataframe:\")\n",
    "print(\"Departure dataframe length: \" + str(len(sch_flow)))\n",
    "sch_flow.set_index('timestamp', inplace=True)\n",
    "print(sch_flow.head())\n",
    "\n",
    "#Display information about the temperature dataset\n",
    "print(\"\\n\\nTemperature dataframe:\")\n",
    "print(\"Temperature dataframe length: \" + str(len(sch_temp)))\n",
    "sch_temp.set_index('timestamp', inplace=True)\n",
    "print(sch_temp.head())\n",
    "\n",
    "\n",
    "sch_merged = sch_flow.join(sch_temp)\n",
    "\n",
    "#Add timestamp back as a column\n",
    "#sch_merged['timestamp'] = sch_merged.index\n",
    "\n",
    "#Display information about the merged dataset\n",
    "print(\"\\n\\nMerged dataset:\")\n",
    "print(\"Merged dataset length: \" + str(len(sch_merged)))\n",
    "print(sch_merged.head(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-43cd3a408be6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msch_merged_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msch_merged_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#sch_merged_final.insert(sch_merged_final.shape[1], 'Humidity', )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msch_humid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msch_humid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msch_merged_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msch_humid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msch_merged_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mYields\u001b[0m \u001b[0mBytestring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPy2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnicode\u001b[0m \u001b[0mString\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpy3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \"\"\"\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__unicode__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__bytes__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__unicode__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         self.to_string(buf=buf, max_rows=max_rows, max_cols=max_cols,\n\u001b[1;32m--> 634\u001b[1;33m                        line_width=width, show_dimensions=show_dimensions)\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_string\u001b[1;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width)\u001b[0m\n\u001b[0;32m    719\u001b[0m                                            \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                                            line_width=line_width)\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_string\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    592\u001b[0m                          .format(name=type(self.frame).__name__,\n\u001b[0;32m    593\u001b[0m                          \u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpprint_thing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m                          idx=pprint_thing(frame.index)))\n\u001b[0m\u001b[0;32m    595\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo_line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\printing.py\u001b[0m in \u001b[0;36mpprint_thing\u001b[1;34m(thing, _nest_lvl, escape_chars, default_escapes, quote_strings, max_seq_items)\u001b[0m\n\u001b[0;32m    218\u001b[0m         result = _pprint_seq(thing, _nest_lvl, escape_chars=escape_chars,\n\u001b[0;32m    219\u001b[0m                              \u001b[0mquote_strings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquote_strings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                              max_seq_items=max_seq_items)\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mquote_strings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\printing.py\u001b[0m in \u001b[0;36m_pprint_seq\u001b[1;34m(seq, _nest_lvl, max_seq_items, **kwds)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mnitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_seq_items\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_seq_items\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     \u001b[1;31m# handle sets, no slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     r = [pprint_thing(next(s),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \"\"\"\n\u001b[0;32m   1125\u001b[0m         \u001b[1;31m# We are explicity making element iterators.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sch_merged_final = sch_merged.groupby([sch_merged.index]).agg({'flow': np.sum, 'arrivals': np.sum, 'departures':np.sum, 'temperature': np.mean})\n",
    "sch_merged_final['timestamp'] = sch_merged_final.index\n",
    "#sch_merged_final.insert(sch_merged_final.shape[1], 'Humidity', )\n",
    "print([sch_humid.loc[sch_humid['timestamp'] == str(timestamp)] for timestamp in sch_merged_final['timestamp']])\n",
    "sch_humid.head()\n",
    "print(sch_merged_final.head(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as a CSV file\n",
    "sch_merged_final.to_csv('data/cleaned/schwartau/schwartau.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
