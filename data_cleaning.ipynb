{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_flow = pd.read_csv(\"data/raw/schwartau/flow_schwartau.csv\")\n",
    "test_flow = sch_flow\n",
    "sch_temp = pd.read_csv(\"data/raw/schwartau/temperature_schwartau.csv\")\n",
    "test_sch = sch_temp\n",
    "sch_humid = pd.read_csv(\"data/raw/schwartau/humidity_schwartau.csv\")\n",
    "sch_weight = pd.read_csv(\"data/raw/schwartau/weight_schwartau.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pls love me I need it to survive -Derek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for flow:\n",
    "\n",
    "* Lots of zero data\n",
    "* Measured every minute. Need to aggregate\n",
    "* Negative numbers are bee departures\n",
    "* Positive numbers are bee arrivals\n",
    "* Keep arrivals and departures separate \n",
    "\n",
    "I separated by every 15 like the temp data and then created 2 df copies for all arrivals and all departures.  DONE-Derek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe: \n",
      "             timestamp  flow\n",
      "0  2017-01-01 14:15:00     0\n",
      "1  2017-01-01 14:16:00     0\n",
      "2  2017-01-01 14:17:00     0\n",
      "3  2017-01-01 14:18:00     0\n",
      "4  2017-01-01 14:19:00     0\n",
      "\n",
      "New dataframe:\n",
      "            timestamp  flow  departures  arrivals\n",
      "0 2017-01-01 14:15:00     0           0         0\n",
      "1 2017-01-01 14:30:00     0           0         0\n",
      "2 2017-01-01 14:45:00     0           0         0\n",
      "3 2017-01-01 15:00:00     0           0         0\n",
      "4 2017-01-01 15:15:00     0           0         0\n",
      "\n",
      "You are a coding master! No problems detected!\n"
     ]
    }
   ],
   "source": [
    "#original flow\n",
    "print(\"Original dataframe: \")\n",
    "print(test_flow.head())\n",
    "print()\n",
    "\n",
    "#Required changes:\n",
    "#Rather than dropping all data that doesn't occur every 15 minutes, we need to sum up departures and arrivals\n",
    "#that occur in each 15 minute timespan. \n",
    "\n",
    "#Track which indexes should be dropped\n",
    "dropList = []\n",
    "\n",
    "#Drop N/A data points\n",
    "sch_flow = sch_flow.dropna()\n",
    "\n",
    "#Convert the timestamps to date time objects\n",
    "sch_flow['timestamp'] = pd.to_datetime(sch_flow['timestamp'])\n",
    "\n",
    "#Create columns for departures and arrivals\n",
    "sch_flow['departures'] = sch_flow['flow']\n",
    "sch_flow['arrivals'] = sch_flow['flow']\n",
    "\n",
    "#Counters for arrivals in each 15 minute interval\n",
    "arrivals = 0\n",
    "departures = 0\n",
    "total_flow = 0\n",
    "\n",
    "#Set the length of the interval\n",
    "interval_length = 15\n",
    "\n",
    "for ind,minute in sch_flow['timestamp'].dt.minute.items():   \n",
    "    #Count the toal flow, departures, and arrival for the current interval\n",
    "    current_flow = sch_flow.at[ind, 'flow']\n",
    "    total_flow += current_flow\n",
    "    if(current_flow < 0):\n",
    "        #Departures are negative flow numbers\n",
    "        departures += abs(current_flow)\n",
    "    else:\n",
    "        arrivals += current_flow\n",
    "    \n",
    "    #Set the values at each 15 minute interval\n",
    "    if(minute % interval_length == 0):\n",
    "        #Set total flow\n",
    "        sch_flow.at[ind, 'flow'] = total_flow\n",
    "        \n",
    "        #Set departures \n",
    "        sch_flow.at[ind, 'departures'] = departures\n",
    "        \n",
    "        #Set arrivals\n",
    "        sch_flow.at[ind, 'arrivals'] = arrivals\n",
    "        \n",
    "        #Reset the counters\n",
    "        total_flow = 0\n",
    "        departures = 0\n",
    "        arrivals = 0\n",
    "    \n",
    "    #Mark indexes that aren't at 15 minute intervals to be dropped\n",
    "    if (minute % interval_length != 0):\n",
    "        dropList.append(ind)\n",
    "\n",
    "#Drop indexes marked for dropping\n",
    "sch_flow = sch_flow.drop(index = dropList)\n",
    "\n",
    "sch_flow.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Display some information about the new dataframe\n",
    "print(\"New dataframe:\")\n",
    "print(sch_flow.head())\n",
    "print()\n",
    "\n",
    "\n",
    "#Do a quick sanity check that the above operation actually worked\n",
    "#Testing your code is always good!\n",
    "flow_problem_flag = False #Detect problems with the flow calculations\n",
    "filtering_problem_flag = False #Detect problems with filtering out minutes that arent at 15 minute intervals\n",
    "problem_index = 0 #The index where the first problem occured\n",
    "flow_gotten = 0 # The number that the flow actually came out to\n",
    "flow_actual = 0 # The actual flow\n",
    "for ind,minute in sch_flow['timestamp'].dt.minute.items():\n",
    "    \n",
    "    #Add the arrivals and departures\n",
    "    #These should be the same as the total flow\n",
    "    current_count = 0\n",
    "    current_count += sch_flow.at[ind, 'arrivals'] #Arrivals are counted as positive 'flow'\n",
    "    current_count -= sch_flow.at[ind, 'departures'] #Departures are counted as negative 'flow'\n",
    "    \n",
    "    #Check that arrivals are \n",
    "    if(current_count != sch_flow.at[ind, 'flow']):\n",
    "        flow_problem_flag = True\n",
    "        problem_index = ind\n",
    "        flow_gotten = current_count\n",
    "        flow_actual = sch_flow.at[ind, 'flow']\n",
    "        break\n",
    "    \n",
    "    if(minute % interval_length != 0):\n",
    "        filtering_problem_flag = True\n",
    "        problem_index = ind\n",
    "        break\n",
    "    \n",
    "if(flow_problem_flag):\n",
    "    print(\"Looks like you have a flow problem at index: \" + str(problem_index) + \"! Have fun with that...\")\n",
    "    print(\"The flow count gotten: \" + str(flow_gotten))\n",
    "    print(\"The flow count expected: \" + str(flow_actual))\n",
    "elif(filtering_problem_flag):\n",
    "    print(\"Looks like you have a time filtering problem at index: \" + str(problem_index) + \"! Have fun with that...\")\n",
    "else:\n",
    "    print(\"You are a coding master! No problems detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for temperature:\n",
    "\n",
    "* May contain NaN (Dropped rows containing these.  DONE-Derek)\n",
    "* Measured in degrees celsius (Will leave as C unless otherwise stated.  DONE-Derek)\n",
    "* Measured every 5 minutes (coverted to every 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  temperature\n",
      "0  2017-01-01 14:10:00          NaN\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "2  2017-01-01 14:20:00       12.270\n",
      "3  2017-01-01 14:25:00       12.276\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "\n",
      "253430\n",
      "\n",
      "251398\n",
      "\n",
      "             timestamp  temperature\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "2  2017-01-01 14:20:00       12.270\n",
      "3  2017-01-01 14:25:00       12.276\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "5  2017-01-01 14:35:00       12.404\n",
      "\n",
      "             timestamp  temperature\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "7  2017-01-01 14:45:00       12.492\n",
      "10 2017-01-01 15:00:00       12.454\n",
      "13 2017-01-01 15:15:00       12.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Preview of temp\n",
    "print(test_sch.head())\n",
    "print()\n",
    "#Initial number of values\n",
    "print(len(test_sch.index))\n",
    "#Drop NaN value rows\n",
    "sch_tempFilter = test_sch.dropna()\n",
    "print()\n",
    "#Number of values after\n",
    "print(len(sch_tempFilter.index))\n",
    "print()\n",
    "print(sch_tempFilter.head())\n",
    "print()\n",
    "\n",
    "#Sorting timestamp...\n",
    "tempList = []\n",
    "sch_temp = sch_temp.dropna()\n",
    "sch_temp['timestamp'] = pd.to_datetime(sch_temp['timestamp'])\n",
    "for ind,minute in sch_temp['timestamp'].dt.minute.items():\n",
    "    if (minute %15 != 0):\n",
    "        tempList.append(ind)\n",
    "sch_temp = sch_temp.drop(index = tempList)\n",
    "\n",
    "#sch_temp.reset_index()\n",
    "\n",
    "print(sch_temp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for humidity:\n",
    "\n",
    "* Measured in percentage\n",
    "* Measured twice per day\n",
    "* May need to be suplimented with other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 13:00:00</td>\n",
       "      <td>98.040310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>98.610556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02 13:00:00</td>\n",
       "      <td>99.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03 01:00:00</td>\n",
       "      <td>98.486806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-03 13:00:00</td>\n",
       "      <td>98.320139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp   humidity\n",
       "0  2017-01-01 13:00:00  98.040310\n",
       "1  2017-01-02 01:00:00  98.610556\n",
       "2  2017-01-02 13:00:00  99.002083\n",
       "3  2017-01-03 01:00:00  98.486806\n",
       "4  2017-01-03 13:00:00  98.320139"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch_humid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for weight:\n",
    "\n",
    "* Measured twice per day. Need some creative solution here\n",
    "* Potential to correlate with flow?\n",
    "* The weight for schwartau needs to be divided by 1000. It was measured in grams accidentally. DONE-Derek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp        weight\n",
      "0  2017-01-01 13:00:00  50736.790078\n",
      "1  2017-01-02 01:00:00  50700.685000\n",
      "2  2017-01-02 13:00:00  50614.907500\n",
      "3  2017-01-03 01:00:00  50739.824167\n",
      "4  2017-01-03 13:00:00  50799.746944\n",
      "\n",
      "             timestamp     weight\n",
      "0  2017-01-01 13:00:00  50.736790\n",
      "1  2017-01-02 01:00:00  50.700685\n",
      "2  2017-01-02 13:00:00  50.614908\n",
      "3  2017-01-03 01:00:00  50.739824\n",
      "4  2017-01-03 13:00:00  50.799747\n"
     ]
    }
   ],
   "source": [
    "#original data\n",
    "test_weight = sch_weight\n",
    "print(test_weight.head())\n",
    "print()\n",
    "#fixing weight\n",
    "sch_weight[\"weight\"] = sch_weight[\"weight\"].div(1000)\n",
    "print(sch_weight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Finally, combine the cleaned dataset into one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Departure dataframe:\n",
      "Departure dataframe length: 167584\n",
      "                     flow  departures  arrivals\n",
      "timestamp                                      \n",
      "2017-01-01 14:15:00     0           0         0\n",
      "2017-01-01 14:30:00     0           0         0\n",
      "2017-01-01 14:45:00     0           0         0\n",
      "2017-01-01 15:00:00     0           0         0\n",
      "2017-01-01 15:15:00     0           0         0\n",
      "\n",
      "\n",
      "Temperature dataframe:\n",
      "Temperature dataframe length: 83800\n",
      "                     temperature\n",
      "timestamp                       \n",
      "2017-01-01 14:15:00       12.340\n",
      "2017-01-01 14:30:00       12.356\n",
      "2017-01-01 14:45:00       12.492\n",
      "2017-01-01 15:00:00       12.454\n",
      "2017-01-01 15:15:00       12.378\n",
      "\n",
      "\n",
      "Merged dataset:\n",
      "Merged dataset length: 167616\n",
      "                     flow  departures  arrivals  temperature\n",
      "timestamp                                                   \n",
      "2017-01-01 14:15:00     0           0         0       12.340\n",
      "2017-01-01 14:15:00     0           0         0       12.340\n",
      "2017-01-01 14:30:00     0           0         0       12.356\n",
      "2017-01-01 14:30:00     0           0         0       12.356\n",
      "2017-01-01 14:45:00     0           0         0       12.492\n",
      "...                   ...         ...       ...          ...\n",
      "2017-01-11 23:30:00     0           0         0       14.472\n",
      "2017-01-11 23:45:00    -1           1         0       16.076\n",
      "2017-01-11 23:45:00     0           0         0       16.076\n",
      "2017-01-12 00:00:00     0           0         0       15.156\n",
      "2017-01-12 00:00:00     0           0         0       15.156\n",
      "\n",
      "[2000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Display information about the flow dataset\n",
    "print(\"\\n\\nDeparture dataframe:\")\n",
    "print(\"Departure dataframe length: \" + str(len(sch_flow)))\n",
    "sch_flow.set_index('timestamp', inplace=True)\n",
    "print(sch_flow.head())\n",
    "\n",
    "#Display information about the temperature dataset\n",
    "print(\"\\n\\nTemperature dataframe:\")\n",
    "print(\"Temperature dataframe length: \" + str(len(sch_temp)))\n",
    "sch_temp.set_index('timestamp', inplace=True)\n",
    "print(sch_temp.head())\n",
    "\n",
    "\n",
    "sch_merged = sch_flow.join(sch_temp)\n",
    "\n",
    "#Add timestamp back as a column\n",
    "#sch_merged['timestamp'] = sch_merged.index\n",
    "\n",
    "#Display information about the merged dataset\n",
    "print(\"\\n\\nMerged dataset:\")\n",
    "print(\"Merged dataset length: \" + str(len(sch_merged)))\n",
    "print(sch_merged.head(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     flow  arrivals  departures  temperature  \\\n",
      "timestamp                                                      \n",
      "2017-01-01 14:15:00     0         0           0       12.340   \n",
      "2017-01-01 14:30:00     0         0           0       12.356   \n",
      "2017-01-01 14:45:00     0         0           0       12.492   \n",
      "2017-01-01 15:00:00     0         0           0       12.454   \n",
      "2017-01-01 15:15:00     0         0           0       12.378   \n",
      "...                   ...       ...         ...          ...   \n",
      "2017-01-03 15:00:00    -1         0           1       14.220   \n",
      "2017-01-03 15:15:00    -1         0           1       19.180   \n",
      "2017-01-03 15:30:00    -1         0           1       18.756   \n",
      "2017-01-03 15:45:00     0         0           0       17.122   \n",
      "2017-01-03 16:00:00    -1         0           1       21.110   \n",
      "\n",
      "                              timestamp  \n",
      "timestamp                                \n",
      "2017-01-01 14:15:00 2017-01-01 14:15:00  \n",
      "2017-01-01 14:30:00 2017-01-01 14:30:00  \n",
      "2017-01-01 14:45:00 2017-01-01 14:45:00  \n",
      "2017-01-01 15:00:00 2017-01-01 15:00:00  \n",
      "2017-01-01 15:15:00 2017-01-01 15:15:00  \n",
      "...                                 ...  \n",
      "2017-01-03 15:00:00 2017-01-03 15:00:00  \n",
      "2017-01-03 15:15:00 2017-01-03 15:15:00  \n",
      "2017-01-03 15:30:00 2017-01-03 15:30:00  \n",
      "2017-01-03 15:45:00 2017-01-03 15:45:00  \n",
      "2017-01-03 16:00:00 2017-01-03 16:00:00  \n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "sch_merged_final = sch_merged.groupby([sch_merged.index]).agg({'flow': np.sum, 'arrivals': np.sum, 'departures':np.sum, 'temperature': np.mean})\n",
    "sch_merged_final['timestamp'] = sch_merged_final.index\n",
    "\n",
    "print(sch_merged_final.head(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as a CSV file\n",
    "sch_merged_final.to_csv('data/cleaned/schwartau/schwartau.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
