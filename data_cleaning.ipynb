{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_flow = pd.read_csv(\"data/raw/schwartau/flow_schwartau.csv\")\n",
    "test_flow = sch_flow\n",
    "sch_temp = pd.read_csv(\"data/raw/schwartau/temperature_schwartau.csv\")\n",
    "test_sch = sch_temp\n",
    "sch_humid = pd.read_csv(\"data/raw/schwartau/humidity_schwartau.csv\")\n",
    "sch_weight = pd.read_csv(\"data/raw/schwartau/weight_schwartau.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pls love me I need it to survive -Derek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for flow:\n",
    "\n",
    "* Lots of zero data\n",
    "* Measured every minute. Need to aggregate\n",
    "* Negative numbers are bee departures\n",
    "* Positive numbers are bee arrivals\n",
    "* Keep arrivals and departures separate \n",
    "\n",
    "I separated by every 15 like the temp data and then created 2 df copies for all arrivals and all departures.  DONE-Derek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  flow\n",
      "0  2017-01-01 14:15:00     0\n",
      "1  2017-01-01 14:16:00     0\n",
      "2  2017-01-01 14:17:00     0\n",
      "3  2017-01-01 14:18:00     0\n",
      "4  2017-01-01 14:19:00     0\n",
      "\n",
      "             timestamp  flow\n",
      "0  2017-01-01 14:15:00     0\n",
      "15 2017-01-01 14:30:00     0\n",
      "30 2017-01-01 14:45:00     0\n",
      "45 2017-01-01 15:00:00     0\n",
      "60 2017-01-01 15:15:00     0\n",
      "\n",
      "                  timestamp  arrivals\n",
      "1297343 2017-01-29 16:00:00         1\n",
      "1305833 2017-02-04 13:30:00         1\n",
      "1323308 2017-02-16 16:45:00         1\n",
      "1324598 2017-02-17 14:15:00         1\n",
      "1324733 2017-02-17 16:30:00         2\n",
      "               timestamp  departures\n",
      "1200 2017-01-02 10:15:00           1\n",
      "1590 2017-01-02 16:45:00           1\n",
      "2775 2017-01-03 12:30:00           1\n",
      "4155 2017-01-04 11:30:00           1\n",
      "9585 2017-01-08 06:00:00           1\n",
      "             timestamp  flow\n",
      "0  2017-01-01 14:15:00     0\n",
      "15 2017-01-01 14:30:00     0\n",
      "30 2017-01-01 14:45:00     0\n",
      "45 2017-01-01 15:00:00     0\n",
      "60 2017-01-01 15:15:00     0\n"
     ]
    }
   ],
   "source": [
    "#original flow\n",
    "print(test_flow.head())\n",
    "print()\n",
    "\n",
    "#Required changes:\n",
    "#Rather than dropping all data that doesn't occur every 15 minutes, we need to sum up departures and arrivals\n",
    "#that occur in each 15 minute timespan. \n",
    "\n",
    "#convert to every 15 min\n",
    "tempList = []\n",
    "sch_flow = sch_flow.dropna()\n",
    "sch_flow['timestamp'] = pd.to_datetime(sch_flow['timestamp'])\n",
    "    if (minute %15 != 0):\n",
    "        tempList.append(ind)\n",
    "sch_flow = sch_flow.drop(index = tempList)\n",
    "print(sch_flow.head())\n",
    "print()\n",
    "\n",
    "#separate out arrivals and departures in separte dataframes\n",
    "sch_flowArrival = sch_flow[sch_flow[\"flow\"] > 0]\n",
    "sch_flowDepart = sch_flow[sch_flow[\"flow\"] < 0]\n",
    "sch_flow = sch_flow[sch_flow[\"flow\"] == 0]\n",
    "\n",
    "#Take the absolute value of the departures dataframe\n",
    "#This way the number of arrivals isn't a negative number\n",
    "sch_flowDepart[\"flow\"] = sch_flowDepart[\"flow\"].abs()\n",
    "\n",
    "#Rename the columns of the arrival and departure dataframes\n",
    "sch_flowArrival.rename(columns={\"flow\":\"arrivals\"}, inplace=True)\n",
    "sch_flowDepart.rename(columns={\"flow\":\"departures\"}, inplace=True)\n",
    "\n",
    "print(sch_flowArrival.head())\n",
    "print(sch_flowDepart.head())\n",
    "print(sch_flow.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for temperature:\n",
    "\n",
    "* May contain NaN (Dropped rows containing these.  DONE-Derek)\n",
    "* Measured in degrees celsius (Will leave as C unless otherwise stated.  DONE-Derek)\n",
    "* Measured every 5 minutes (coverted to every 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  temperature\n",
      "0  2017-01-01 14:10:00          NaN\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "2  2017-01-01 14:20:00       12.270\n",
      "3  2017-01-01 14:25:00       12.276\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "\n",
      "253430\n",
      "\n",
      "251398\n",
      "\n",
      "             timestamp  temperature\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "2  2017-01-01 14:20:00       12.270\n",
      "3  2017-01-01 14:25:00       12.276\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "5  2017-01-01 14:35:00       12.404\n",
      "\n",
      "             timestamp  temperature\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "7  2017-01-01 14:45:00       12.492\n",
      "10 2017-01-01 15:00:00       12.454\n",
      "13 2017-01-01 15:15:00       12.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Preview of temp\n",
    "print(test_sch.head())\n",
    "print()\n",
    "#Initial number of values\n",
    "print(len(test_sch.index))\n",
    "#Drop NaN value rows\n",
    "sch_tempFilter = test_sch.dropna()\n",
    "print()\n",
    "#Number of values after\n",
    "print(len(sch_tempFilter.index))\n",
    "print()\n",
    "print(sch_tempFilter.head())\n",
    "print()\n",
    "\n",
    "#Sorting timestamp...\n",
    "tempList = []\n",
    "sch_temp = sch_temp.dropna()\n",
    "sch_temp['timestamp'] = pd.to_datetime(sch_temp['timestamp'])\n",
    "for ind,minute in sch_temp['timestamp'].dt.minute.items():\n",
    "    if (minute %15 != 0):\n",
    "        tempList.append(ind)\n",
    "sch_temp = sch_temp.drop(index = tempList)\n",
    "\n",
    "#sch_temp.reset_index()\n",
    "\n",
    "print(sch_temp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for humidity:\n",
    "\n",
    "* Measured in percentage\n",
    "* Measured twice per day\n",
    "* May need to be suplimented with other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 13:00:00</td>\n",
       "      <td>98.040310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-02 01:00:00</td>\n",
       "      <td>98.610556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02 13:00:00</td>\n",
       "      <td>99.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03 01:00:00</td>\n",
       "      <td>98.486806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-03 13:00:00</td>\n",
       "      <td>98.320139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp   humidity\n",
       "0  2017-01-01 13:00:00  98.040310\n",
       "1  2017-01-02 01:00:00  98.610556\n",
       "2  2017-01-02 13:00:00  99.002083\n",
       "3  2017-01-03 01:00:00  98.486806\n",
       "4  2017-01-03 13:00:00  98.320139"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch_humid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Cleaning notes for weight:\n",
    "\n",
    "* Measured twice per day. Need some creative solution here\n",
    "* Potential to correlate with flow?\n",
    "* The weight for schwartau needs to be divided by 1000. It was measured in grams accidentally. DONE-Derek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp        weight\n",
      "0  2017-01-01 13:00:00  50736.790078\n",
      "1  2017-01-02 01:00:00  50700.685000\n",
      "2  2017-01-02 13:00:00  50614.907500\n",
      "3  2017-01-03 01:00:00  50739.824167\n",
      "4  2017-01-03 13:00:00  50799.746944\n",
      "\n",
      "             timestamp     weight\n",
      "0  2017-01-01 13:00:00  50.736790\n",
      "1  2017-01-02 01:00:00  50.700685\n",
      "2  2017-01-02 13:00:00  50.614908\n",
      "3  2017-01-03 01:00:00  50.739824\n",
      "4  2017-01-03 13:00:00  50.799747\n"
     ]
    }
   ],
   "source": [
    "#original data\n",
    "test_weight = sch_weight\n",
    "print(test_weight.head())\n",
    "print()\n",
    "#fixing weight\n",
    "sch_weight[\"weight\"] = sch_weight[\"weight\"].div(1000)\n",
    "print(sch_weight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Finally, combine the cleaned dataset into one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrival dataframe:\n",
      "Arrival dataframe length: 35845\n",
      "                  timestamp  arrivals\n",
      "1297343 2017-01-29 16:00:00         1\n",
      "1305833 2017-02-04 13:30:00         1\n",
      "1323308 2017-02-16 16:45:00         1\n",
      "1324598 2017-02-17 14:15:00         1\n",
      "1324733 2017-02-17 16:30:00         2\n",
      "\n",
      "\n",
      "Departure dataframe:\n",
      "Departure dataframe length: 36228\n",
      "               timestamp  departures\n",
      "1200 2017-01-02 10:15:00           1\n",
      "1590 2017-01-02 16:45:00           1\n",
      "2775 2017-01-03 12:30:00           1\n",
      "4155 2017-01-04 11:30:00           1\n",
      "9585 2017-01-08 06:00:00           1\n",
      "\n",
      "\n",
      "Temperature dataframe:\n",
      "Temperature dataframe length: 83800\n",
      "             timestamp  temperature\n",
      "1  2017-01-01 14:15:00       12.340\n",
      "4  2017-01-01 14:30:00       12.356\n",
      "7  2017-01-01 14:45:00       12.492\n",
      "10 2017-01-01 15:00:00       12.454\n",
      "13 2017-01-01 15:15:00       12.378\n",
      "\n",
      "\n",
      "Merged dataset:\n",
      "Merged dataset length: 36228\n",
      "            timestamp  departures  arrivals\n",
      "0 2017-01-02 10:15:00           1       NaN\n",
      "1 2017-01-02 16:45:00           1       NaN\n",
      "2 2017-01-03 12:30:00           1       NaN\n",
      "3 2017-01-04 11:30:00           1       NaN\n",
      "4 2017-01-08 06:00:00           1       NaN\n",
      "\n",
      "\n",
      "Merged dataset:\n",
      "Merged dataset length: 83800\n",
      "            timestamp  temperature  departures  arrivals\n",
      "0 2017-01-01 14:15:00       12.340         NaN       NaN\n",
      "1 2017-01-01 14:30:00       12.356         NaN       NaN\n",
      "2 2017-01-01 14:45:00       12.492         NaN       NaN\n",
      "3 2017-01-01 15:00:00       12.454         NaN       NaN\n",
      "4 2017-01-01 15:15:00       12.378         NaN       NaN\n",
      "                timestamp  temperature  departures  arrivals\n",
      "80    2017-01-02 10:15:00       12.516         1.0       NaN\n",
      "106   2017-01-02 16:45:00       11.332         1.0       NaN\n",
      "185   2017-01-03 12:30:00       20.694         1.0       NaN\n",
      "277   2017-01-04 11:30:00       20.028         1.0       NaN\n",
      "639   2017-01-08 06:00:00        8.600         1.0       NaN\n",
      "...                   ...          ...         ...       ...\n",
      "83751 2019-05-31 02:15:00       33.928         1.0       1.0\n",
      "83753 2019-05-31 02:45:00       34.176         1.0       1.0\n",
      "83758 2019-05-31 04:00:00       34.036         1.0       1.0\n",
      "83767 2019-05-31 06:15:00       33.714         1.0       4.0\n",
      "83769 2019-05-31 06:45:00       34.016         1.0       3.0\n",
      "\n",
      "[2639 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Display information about the flow arrival dataset\n",
    "print(\"Arrival dataframe:\")\n",
    "print(\"Arrival dataframe length: \" + str(len(sch_flowArrival)))\n",
    "print(sch_flowArrival.head())\n",
    "\n",
    "#Display information about the flow departure dataset\n",
    "print(\"\\n\\nDeparture dataframe:\")\n",
    "print(\"Departure dataframe length: \" + str(len(sch_flowDepart)))\n",
    "print(sch_flowDepart.head())\n",
    "\n",
    "#Display information about the temperature dataset\n",
    "print(\"\\n\\nTemperature dataframe:\")\n",
    "print(\"Temperature dataframe length: \" + str(len(sch_temp)))\n",
    "print(sch_temp.head())\n",
    "\n",
    "#Merge the datasets together\n",
    "sch_merged = pd.merge_asof(sch_flowDepart, sch_flowArrival, on='timestamp', by='timestamp')\n",
    "sch_merged = sch_merged.sort_values(by='timestamp', ascending=True)\n",
    "sch_temp = sch_temp.sort_values(by='timestamp', ascending=True)\n",
    "\n",
    "#Display information about the merged dataset\n",
    "print(\"\\n\\nMerged dataset:\")\n",
    "print(\"Merged dataset length: \" + str(len(sch_merged)))\n",
    "print(sch_merged.head())\n",
    "\n",
    "sch_merged = pd.merge_asof(sch_temp, sch_merged, on='timestamp', by='timestamp')\n",
    "\n",
    "#Display information about the merged dataset\n",
    "print(\"\\n\\nMerged dataset:\")\n",
    "print(\"Merged dataset length: \" + str(len(sch_merged)))\n",
    "print(sch_merged.head())\n",
    "\n",
    "#Unsure if this is valid yet. Shouldn't be, but I need to check.\n",
    "print(sch_merged.loc[sch_merged['departures'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
